{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "\n",
    "def jsonl_reader(input_file):\n",
    "    data = []\n",
    "    with jsonlines.open(input_file) as reader:\n",
    "        for obj in reader:\n",
    "            data.append(obj)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to count number of sentences and words in a paragraph\n",
    "\n",
    "def count_sentences_words(paragraph):\n",
    "    sentences = paragraph.split('.')\n",
    "    num_sentences = len(sentences)\n",
    "    num_words = 0\n",
    "    for sentence in sentences:\n",
    "        num_words += len(sentence.split())\n",
    "    return {'num_sentences': num_sentences, 'num_words': num_words}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `raw_data/hotpotqa/wikpedia-paragraphs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "\n",
    "with bz2.open(\"raw_data/hotpotqa/wikpedia-paragraphs/AA/wiki_00.bz2\", \"rt\") as bzinput:\n",
    "    data = bzinput.read()\n",
    "    print(type(data))\n",
    "    print(data[1000:2000])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `processed_data/hotpotqa/train.jsonl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = jsonl_reader('processed_data/hotpotqa/train.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data))\n",
    "print(data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0]['level'])\n",
    "print(data[0]['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]['answers_objects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of contexts: {len(data[0]['contexts'])}\")\n",
    "data[0]['contexts'][2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_sentences_words(data[0]['contexts'][2]['paragraph_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_words_list = [] # for plotting histogram\n",
    "max_num_words = 0\n",
    "max_idx = 0\n",
    "min_num_words = 1000000\n",
    "min_idx = 0\n",
    "num_samples = len(data)\n",
    "\n",
    "for sample in data:\n",
    "    for context in sample['contexts']:\n",
    "        num_words = count_sentences_words(context['paragraph_text'])['num_words']\n",
    "        num_words_list.append(num_words)\n",
    "        if num_words > max_num_words:\n",
    "            max_num_words = num_words\n",
    "        if num_words < min_num_words:\n",
    "            min_num_words = num_words\n",
    "\n",
    "print(f\"Number of samples: {num_samples}\")\n",
    "print(f\"Max number of words: {max_num_words}\")\n",
    "print(f\"max_idx: {max_idx}\")\n",
    "print(f\"Min number of words: {min_num_words}\")\n",
    "print(f\"min_idx: {min_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(num_words_list, bins=100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `annotated_only_train.jsonl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = jsonl_reader('processed_data/hotpotqa/annotated_only_train.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]['question_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]['answers_objects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of contexts: {len(data[0]['contexts'])}\")\n",
    "data[0]['contexts'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]['reasoning_steps']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each predicted paragraph, check if the gold paragraph is in the list of predicted paragraphs\n",
    "# if yes, identify the index of the gold paragraph in the list of predicted answers\n",
    "# if no, set the index to -1\n",
    "# then, plot the histogram of the indices\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def get_idx_count(predicted_file_name, gold_answers_file_name):\n",
    "    # load them as dict\n",
    "    with open(predicted_file_name) as f:\n",
    "        predicted_answers = json.load(f)\n",
    "\n",
    "    with open(gold_answers_file_name) as f:\n",
    "        gold_answers = json.load(f)\n",
    "\n",
    "    from collections import defaultdict\n",
    "    idx_count = defaultdict(int)\n",
    "    for key in predicted_answers.keys():\n",
    "        gold_paragraphs = gold_answers[key]\n",
    "        predicted_paragraphs = predicted_answers[key]\n",
    "        for gold_paragraph in gold_paragraphs:\n",
    "            if gold_paragraph in predicted_paragraphs:\n",
    "                idx = predicted_paragraphs.index(gold_paragraph)\n",
    "            else:\n",
    "                idx = -1\n",
    "            idx_count[idx] += 1\n",
    "    idx_count = dict(sorted(idx_count.items()))\n",
    "    return idx_count\n",
    "\n",
    "def get_file_name_given_sim_threshold(threshold=90):\n",
    "    predicted_file_name = f'predictions_saved/sim_{threshold}/ircot_flan_t5_large_hotpotqa____ircot____hotpotqa_to_hotpotqa__best/prediction__hotpotqa_to_hotpotqa__test_subsampled.json'\n",
    "    gold_file_name = f'predictions_saved/sim_{threshold}/ircot_flan_t5_large_hotpotqa____ircot____hotpotqa_to_hotpotqa__best/ground_truth__hotpotqa_to_hotpotqa__test_subsampled.json'\n",
    "    \n",
    "    assert os.path.isfile(predicted_file_name), f\"File not found: {predicted_file_name}\"\n",
    "    \n",
    "    return predicted_file_name, gold_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" get the counts of all indices for different similarity thresholds. \"\"\"\n",
    "\n",
    "sim_thresholds = [90, 95]\n",
    "idx_counts = []\n",
    "\n",
    "for sim_threshold in sim_thresholds:\n",
    "    predicted_file_name, gold_file_name = get_file_name_given_sim_threshold(sim_threshold)\n",
    "    idx_count = get_idx_count(predicted_file_name, gold_file_name)\n",
    "    idx_counts.append(idx_count)\n",
    "\n",
    "indices = list(idx_counts[0].keys())\n",
    "\n",
    "print(idx_counts)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write sim_thresholds and idx_counts into csv\n",
    "# where each row is a sim_threshold\n",
    "# and columns are indices\n",
    "\n",
    "\n",
    "output_path = 'sim_thresholds_idx_counts.csv'\n",
    "with open(output_path, 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['sim_threshold'] + indices)\n",
    "    for i in range(len(sim_thresholds)):\n",
    "        writer.writerow([sim_thresholds[i]] + [idx_counts[i][idx] for idx in indices])\n",
    "\n",
    "    \n",
    "    print(f'Done writing to {os.path.abspath(output_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_y_pairs = []\n",
    "\n",
    "for idx_count in idx_counts:\n",
    "    x = list(idx_count.keys())\n",
    "    y = list(idx_count.values())\n",
    "    x_y_pairs.append((x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.3\n",
    "\n",
    "all_x = x_y[0]\n",
    "all_x_shift = [x + width for x in all_x]\n",
    "all_x_mid = [(x1 + x2) / 2 for (x1, x2) in zip(all_x, all_x_shift)] # for plotting the xticks\n",
    "\n",
    "all_y = [x_y[1] for x_y in x_y_pairs]\n",
    "plt.bar(all_x, all_y[0], width=width)\n",
    "plt.bar(all_x_shift, all_y[1], width=width)\n",
    "\n",
    "\n",
    "# show the values on top of the bars\n",
    "# for a, b in zip(all_x, all_y[0]):\n",
    "#     plt.text(a-1.5*width, b, str(b))\n",
    "\n",
    "# for a, b in zip(all_x_shift, all_y[1]):\n",
    "#     plt.text(a, b, str(b))\n",
    "\n",
    "\n",
    "# description: plot the histogram of the indices of gold paragraphs in the list of predicted paragraphs\n",
    "plt.title('#samples with gold paragraph at different positions')\n",
    "plt.xlabel('Position of gold paragraph in the list of predicted paragraphs')\n",
    "plt.ylabel('Number of samples')\n",
    "\n",
    "plt.xticks(all_x_mid, all_x)\n",
    "\n",
    "plt.legend(sim_thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Threshold Exp on Retrieval (No QA!!!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exp-1. Read all metrics json file and convert to a csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99, 90, 70, 50, 30]\n",
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "from collections import defaultdict\n",
    "exp2_path = '/home/guest/r11944026/all_ircot/ircot_exp2/ircot'\n",
    "sim_thresholds = [99, 90, 70, 50, 30]\n",
    "retrieval_counts = [1,2,3,4]\n",
    "print(sim_thresholds)\n",
    "print(retrieval_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name_given_sim_threshold(count=30, threshold=90):\n",
    "    # oner\n",
    "    # gold_file_name = os.path.join(exp2_path, f\"predictions_archived/oner/count{count}/oner_hotpotqa_similarity_{threshold}____oner____hotpotqa_to_hotpotqa__best/ground_truth__hotpotqa_to_hotpotqa__test_subsampled.json\")\n",
    "    # predicted_file_name = os.path.join(exp2_path, f\"predictions_archived/oner/count{count}/oner_hotpotqa_similarity_{threshold}____oner____hotpotqa_to_hotpotqa__best/prediction__hotpotqa_to_hotpotqa__test_subsampled.json\")\n",
    "    # oner_qa\n",
    "    predicted_file_name = os.path.join(exp2_path, f'predictions_archived/oner_qa/oner_qa_flan_t5_base_hotpotqa_similarity_{threshold}____prompt_set_1___bm25_retrieval_count__{count}___distractor_count__2/prediction__hotpotqa_to_hotpotqa__dev_subsampled.json')\n",
    "    gold_file_name = os.path.join(exp2_path, f'predictions_archived/oner_qa/oner_qa_flan_t5_base_hotpotqa_similarity_{threshold}____prompt_set_1___bm25_retrieval_count__{count}___distractor_count__2/ground_truth__hotpotqa_to_hotpotqa__dev_subsampled.json')\n",
    "    # predicted_file_name = os.path.join(exp2_path, f'predictions_archived/oner_qa/oner_qa_flan_t5_base_hotpotqa_similarity_{threshold}____oner_qa____hotpotqa_to_hotpotqa__best/prediction__hotpotqa_to_hotpotqa__test_subsampled.json')\n",
    "    # gold_file_name = os.path.join(exp2_path, f'predictions_archived/oner_qa/oner_qa_flan_t5_base_hotpotqa_similarity_{threshold}____oner_qa____hotpotqa_to_hotpotqa__best/ground_truth__hotpotqa_to_hotpotqa__test_subsampled.json')\n",
    "    \n",
    "    assert os.path.isfile(predicted_file_name), f\"File not found: {predicted_file_name}\"\n",
    "    \n",
    "    return predicted_file_name, gold_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_file_name_given_sim_threshold(threshold=90, count=15):\n",
    "    metric_file_name = os.path.join(exp2_path, f'predictions_archived/oner_qa/oner_qa_flan_t5_base_hotpotqa_similarity_{threshold}____prompt_set_1___bm25_retrieval_count__{count}___distractor_count__2/evaluation_metrics__hotpotqa_to_hotpotqa__dev_subsampled.json')\n",
    "    assert os.path.isfile(metric_file_name), f\"File not found: {metric_file_name}\"\n",
    "    return metric_file_name\n",
    "\n",
    "def get_metric_dict(metric_file_name):\n",
    "    with open(metric_file_name) as f:\n",
    "        metric_dict = json.load(f)\n",
    "    return metric_dict\n",
    "\n",
    "def get_threshold_metric_dict(thresholds, count):\n",
    "    threshold_metric_dict = {}\n",
    "    for threshold in thresholds:\n",
    "        metric_file_name = get_metric_file_name_given_sim_threshold(threshold, count)\n",
    "        metric_dict = get_metric_dict(metric_file_name)\n",
    "        threshold_metric_dict[threshold] = metric_dict\n",
    "    return threshold_metric_dict\n",
    "\n",
    "def convert_threshold_metric_dict_to_csv(threshold_metric_dict, count=15):\n",
    "    # threshold_metric_dict: [{threshold1: metric_dict1}, {threshold2: metric_dict2}, ...]\n",
    "    keys = list(threshold_metric_dict[sim_thresholds[0]].keys())\n",
    "    keys.sort()\n",
    "    print(\"keys:\", keys)\n",
    "    output_path = os.path.join(exp2_path, f'results/metric_count_{count}.csv')\n",
    "    with open(output_path, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['sim_threshold'] + keys)\n",
    "        for threshold, metric_dict in threshold_metric_dict.items():\n",
    "            writer.writerow([threshold] + [metric_dict[key] for key in keys])\n",
    "\n",
    "    print(f'Done writing to {os.path.abspath(output_path)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys: ['count', 'em', 'f1', 'git_hash', 'precision', 'recall', 'sp_em', 'sp_f1', 'sp_precision', 'sp_recall']\n",
      "Done writing to /home/guest/r11944026/all_ircot/ircot_exp2/ircot/results/metric_count_1.csv\n",
      "Done for count = 1\n",
      "keys: ['count', 'em', 'f1', 'git_hash', 'precision', 'recall', 'sp_em', 'sp_f1', 'sp_precision', 'sp_recall']\n",
      "Done writing to /home/guest/r11944026/all_ircot/ircot_exp2/ircot/results/metric_count_2.csv\n",
      "Done for count = 2\n",
      "keys: ['count', 'em', 'f1', 'git_hash', 'precision', 'recall', 'sp_em', 'sp_f1', 'sp_precision', 'sp_recall']\n",
      "Done writing to /home/guest/r11944026/all_ircot/ircot_exp2/ircot/results/metric_count_3.csv\n",
      "Done for count = 3\n",
      "keys: ['count', 'em', 'f1', 'git_hash', 'precision', 'recall', 'sp_em', 'sp_f1', 'sp_precision', 'sp_recall']\n",
      "Done writing to /home/guest/r11944026/all_ircot/ircot_exp2/ircot/results/metric_count_4.csv\n",
      "Done for count = 4\n"
     ]
    }
   ],
   "source": [
    "for count in retrieval_counts:\n",
    "    threshold_metric_dict = get_threshold_metric_dict(sim_thresholds, count)\n",
    "    convert_threshold_metric_dict_to_csv(threshold_metric_dict, count)\n",
    "    print(f\"Done for count = {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exp-2. Hit Position / MMR Analysis (kind of like top-K hits?)\n",
    "* Analyze at which index the hit occurs \n",
    "* Calculate MMR (mean reciprocal rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each predicted paragraph, check if the gold paragraph is in the list of predicted paragraphs\n",
    "# if yes, identify the index of the gold paragraph in the list of predicted answers\n",
    "# if no, set the index to -1\n",
    "\n",
    "def get_hit_position(predicted_file_name, gold_answers_file_name):\n",
    "    \"\"\"\n",
    "    predicted_file_name: path to the file containing predicted answers\n",
    "    gold_answers_file_name: path to the file containing gold answers\n",
    "    hit_position: a dict mapping from hit position \n",
    "        (the index of the gold paragraph in the list of predicted paragraphs) \n",
    "        to the number of samples\n",
    "        where -1 means the gold paragraph is not in the list of predicted paragraphs\n",
    "    \"\"\"\n",
    "    with open(predicted_file_name) as f:\n",
    "        predicted_answers = json.load(f)\n",
    "\n",
    "    with open(gold_answers_file_name) as f:\n",
    "        gold_answers = json.load(f)\n",
    "\n",
    "    hit_position = defaultdict(int)\n",
    "    for key in predicted_answers.keys():\n",
    "        gold_paragraphs = gold_answers[key]\n",
    "        predicted_paragraphs = predicted_answers[key]\n",
    "        for gold_paragraph in gold_paragraphs:\n",
    "            if gold_paragraph in predicted_paragraphs:\n",
    "                idx = predicted_paragraphs.index(gold_paragraph)\n",
    "            else:\n",
    "                idx = -1\n",
    "            hit_position[idx] += 1\n",
    "    hit_position = dict(sorted(hit_position.items()))\n",
    "    return hit_position\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_reciprocal_rank(hit_position):\n",
    "    \"\"\"\n",
    "    hit_position: a dict mapping from hit position \n",
    "        (the index of the gold paragraph in the list of predicted paragraphs) \n",
    "        to the number of samples\n",
    "        where -1 means the gold paragraph is not in the list of predicted paragraphs\n",
    "    \"\"\"\n",
    "    mrr_score = 0.0\n",
    "    num_samples = sum(hit_position.values())\n",
    "    # print(f\"num_samples: {num_samples}\")\n",
    "    for position, num_samples_at_position in hit_position.items():\n",
    "        if position == -1:\n",
    "            continue\n",
    "        rr = num_samples_at_position / (position + 1)\n",
    "        mrr_score += rr / num_samples\n",
    "        # print(f\"position: {position}, rr: {rr}\")\n",
    "    return mrr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit_position at count = 1: [{-1: 82, 0: 17, 5: 1, 1: 0, 2: 0, 3: 0, 4: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0}, {-1: 82, 0: 17, 5: 1, 1: 0, 2: 0, 3: 0, 4: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0}, {-1: 82, 0: 17, 5: 1, 1: 0, 2: 0, 3: 0, 4: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0}, {-1: 82, 0: 17, 5: 1, 1: 0, 2: 0, 3: 0, 4: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0}, {-1: 82, 0: 17, 5: 1, 1: 0, 2: 0, 3: 0, 4: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0}]\n",
      "Done writing to /home/guest/r11944026/all_ircot/ircot_exp2/ircot/results/count1_sim_thresholds_hit_positions.csv\n",
      "Done writing to /home/guest/r11944026/all_ircot/ircot_exp2/ircot/results/count1_sim_thresholds_mrr.csv\n",
      "\n",
      "hit_position at count = 2: [{-1: 83, 0: 15, 4: 1, 5: 1, 1: 0, 2: 0, 3: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0}, {-1: 83, 0: 15, 4: 1, 5: 1, 1: 0, 2: 0, 3: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0}, {-1: 83, 0: 15, 4: 1, 5: 1, 1: 0, 2: 0, 3: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0}, {-1: 83, 0: 15, 4: 1, 5: 1, 1: 0, 2: 0, 3: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0}, {-1: 85, 0: 13, 4: 1, 5: 1, 1: 0, 2: 0, 3: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0}]\n",
      "Done writing to /home/guest/r11944026/all_ircot/ircot_exp2/ircot/results/count2_sim_thresholds_hit_positions.csv\n",
      "Done writing to /home/guest/r11944026/all_ircot/ircot_exp2/ircot/results/count2_sim_thresholds_mrr.csv\n",
      "\n",
      "hit_position at count = 3: [{-1: 76, 0: 22, 4: 1, 5: 1, 1: 0, 2: 0, 3: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0}, {-1: 76, 0: 22, 4: 1, 5: 1, 1: 0, 2: 0, 3: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0}, {-1: 76, 0: 22, 4: 1, 5: 1, 1: 0, 2: 0, 3: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0}, {-1: 76, 0: 22, 4: 1, 5: 1, 1: 0, 2: 0, 3: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0}, {-1: 84, 0: 14, 4: 1, 5: 1, 1: 0, 2: 0, 3: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0}]\n",
      "Done writing to /home/guest/r11944026/all_ircot/ircot_exp2/ircot/results/count3_sim_thresholds_hit_positions.csv\n",
      "Done writing to /home/guest/r11944026/all_ircot/ircot_exp2/ircot/results/count3_sim_thresholds_mrr.csv\n",
      "\n",
      "hit_position at count = 4: [{-1: 81, 0: 18, 5: 1, 1: 0, 2: 0, 3: 0, 4: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0}, {-1: 81, 0: 18, 5: 1, 1: 0, 2: 0, 3: 0, 4: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0}, {-1: 81, 0: 18, 5: 1, 1: 0, 2: 0, 3: 0, 4: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0}, {-1: 80, 0: 18, 4: 1, 5: 1, 1: 0, 2: 0, 3: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0}, {-1: 85, 0: 13, 4: 1, 5: 1, 1: 0, 2: 0, 3: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0}]\n",
      "Done writing to /home/guest/r11944026/all_ircot/ircot_exp2/ircot/results/count4_sim_thresholds_hit_positions.csv\n",
      "Done writing to /home/guest/r11944026/all_ircot/ircot_exp2/ircot/results/count4_sim_thresholds_mrr.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" get the counts of all indices for different similarity thresholds. \"\"\"\n",
    "\n",
    "indices = list(range(-1, 15))\n",
    "\n",
    "for count in retrieval_counts:\n",
    "    hit_positions = []\n",
    "    mmrs = []\n",
    "\n",
    "    for sim_threshold in sim_thresholds:\n",
    "        predicted_file_name, gold_file_name = get_file_name_given_sim_threshold(count, sim_threshold)\n",
    "        hit_position = get_hit_position(predicted_file_name, gold_file_name)\n",
    "        \n",
    "        # for those indices that are not in the list, set their counts to 0\n",
    "        for idx in indices:\n",
    "            if idx not in hit_position.keys():\n",
    "                hit_position[idx] = 0\n",
    "\n",
    "        hit_positions.append(hit_position)\n",
    "        mmrs.append(mean_reciprocal_rank(hit_position))\n",
    "    \n",
    "    print(f\"hit_position at count = {count}: {hit_positions}\")\n",
    "\n",
    "    # write sim_thresholds and idx_counts into csv\n",
    "    output_path = os.path.join(exp2_path, f'results/count{count}_sim_thresholds_hit_positions.csv')\n",
    "    with open(output_path, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['sim_threshold'] + indices)\n",
    "        for i in range(len(sim_thresholds)):\n",
    "            writer.writerow([sim_thresholds[i]] + [hit_positions[i][idx] for idx in indices])\n",
    "        print(f'Done writing to {os.path.abspath(output_path)}')\n",
    "\n",
    "    # write mmr into csv\n",
    "    output_path = os.path.join(exp2_path, f'results/count{count}_sim_thresholds_mrr.csv')\n",
    "    with open(output_path, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['sim_threshold', 'mrr'])\n",
    "        for i in range(len(sim_thresholds)):\n",
    "            writer.writerow([sim_thresholds[i], mmrs[i]])\n",
    "        print(f'Done writing to {os.path.abspath(output_path)}')\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exp-3. MAP\n",
    "Calculate mean average precision (MAP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_precision(predicted_file_name, gold_answers_file_name):\n",
    "    \"\"\"\n",
    "    predicted_file_name: path to the file containing predicted answers\n",
    "    gold_answers_file_name: path to the file containing gold answers\n",
    "    \"\"\"\n",
    "    with open(predicted_file_name) as f:\n",
    "        predicted_answers = json.load(f)\n",
    "\n",
    "    with open(gold_answers_file_name) as f:\n",
    "        gold_answers = json.load(f)\n",
    "\n",
    "    average_precision = []\n",
    "    for key in predicted_answers.keys():\n",
    "        gold_paragraphs = gold_answers[key]\n",
    "        predicted_paragraphs = predicted_answers[key]\n",
    "        num_gold_paragraphs = len(gold_paragraphs)\n",
    "        num_predicted_paragraphs = len(predicted_paragraphs)\n",
    "        if num_gold_paragraphs == 0 or num_predicted_paragraphs == 0:\n",
    "            average_precision.append(0)\n",
    "            continue\n",
    "        num_correct = 0\n",
    "        precision = []\n",
    "        for i in range(num_predicted_paragraphs):\n",
    "            if predicted_paragraphs[i] in gold_paragraphs:\n",
    "                num_correct += 1\n",
    "                precision.append(num_correct / (i + 1))\n",
    "        average_precision.append(sum(precision) / num_gold_paragraphs)\n",
    "    # compute mean, std, max, min of average_precision\n",
    "\n",
    "    mean_average_precision = np.mean(average_precision)\n",
    "    std_average_precision = np.std(average_precision)\n",
    "    max_average_precision = np.max(average_precision)\n",
    "    min_average_precision = np.min(average_precision)\n",
    "\n",
    "    return {'mean': mean_average_precision, 'std': std_average_precision, 'max': max_average_precision, 'min': min_average_precision}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count=1, sim_threshold=99, MAP=0.0\n",
      "count=1, sim_threshold=90, MAP=0.0\n",
      "count=1, sim_threshold=70, MAP=0.0\n",
      "count=1, sim_threshold=50, MAP=0.0\n",
      "count=1, sim_threshold=30, MAP=0.0\n",
      "Done writing to /home/guest/r11944026/all_ircot/ircot_exp2/ircot/results/count1_sim_thresholds_map.csv\n",
      "count=2, sim_threshold=99, MAP=0.0\n",
      "count=2, sim_threshold=90, MAP=0.0\n",
      "count=2, sim_threshold=70, MAP=0.0\n",
      "count=2, sim_threshold=50, MAP=0.0\n",
      "count=2, sim_threshold=30, MAP=0.0\n",
      "Done writing to /home/guest/r11944026/all_ircot/ircot_exp2/ircot/results/count2_sim_thresholds_map.csv\n",
      "count=3, sim_threshold=99, MAP=0.0\n",
      "count=3, sim_threshold=90, MAP=0.0\n",
      "count=3, sim_threshold=70, MAP=0.0\n",
      "count=3, sim_threshold=50, MAP=0.0\n",
      "count=3, sim_threshold=30, MAP=0.0\n",
      "Done writing to /home/guest/r11944026/all_ircot/ircot_exp2/ircot/results/count3_sim_thresholds_map.csv\n",
      "count=4, sim_threshold=99, MAP=0.0\n",
      "count=4, sim_threshold=90, MAP=0.0\n",
      "count=4, sim_threshold=70, MAP=0.0\n",
      "count=4, sim_threshold=50, MAP=0.0\n",
      "count=4, sim_threshold=30, MAP=0.0\n",
      "Done writing to /home/guest/r11944026/all_ircot/ircot_exp2/ircot/results/count4_sim_thresholds_map.csv\n"
     ]
    }
   ],
   "source": [
    "for count in retrieval_counts:\n",
    "    for sim_threshold in sim_thresholds:\n",
    "        predicted_file_name, gold_file_name = get_file_name_given_sim_threshold(count, sim_threshold)\n",
    "        map_result = mean_average_precision(predicted_file_name, gold_file_name)\n",
    "        print(f\"count={count}, sim_threshold={sim_threshold}, MAP={map_result['mean']}\")\n",
    "\n",
    "    # write to file\n",
    "    output_path = os.path.join(exp2_path, f'results/count{count}_sim_thresholds_map.csv')\n",
    "    with open(output_path, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['sim_threshold', 'mean', 'std', 'max', 'min'])\n",
    "        for sim_threshold in sim_thresholds:\n",
    "            predicted_file_name, gold_file_name = get_file_name_given_sim_threshold(count, sim_threshold)\n",
    "            map_result = mean_average_precision(predicted_file_name, gold_file_name)\n",
    "            writer.writerow([sim_threshold, map_result['mean'], map_result['std'], map_result['max'], map_result['min']])\n",
    "        print(f'Done writing to {os.path.abspath(output_path)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ircot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
